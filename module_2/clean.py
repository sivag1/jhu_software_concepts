import json
import re
import os

class DataCleaner:
    def __init__(self):
        self.data = []

    def load_data(self, filename="applicant_data.json"):
        """
        Loads raw data from the JSON file generated by scrape.py.
        """
        if not os.path.exists(filename):
            print(f"Error: {filename} not found. Run scrape.py first.")
            return

        with open(filename, 'r', encoding='utf-8') as f:
            self.data = json.load(f)
        print(f"Loaded {len(self.data)} entries from {filename}")

    def clean_data(self):
        """
        Iterates through the dataset to sanitize fields.
        Meets requirement: 'SHOULD ensure data does not include any remnant HTML'
        """
        cleaned_list = []
        
        for entry in self.data:
            cleaned_entry = {}
            for key, value in entry.items():
                if key == "program":
                    cleaned_entry[key] = self._clean_program(value)
                elif key != "raw":
                    cleaned_entry[key] = self._clean_value(value)
                else:
                    extra_data = self.parse_stats(value)
                    for extra_key, extra_value in extra_data.items():
                        cleaned_entry[extra_key] = self._clean_value(extra_value)
            cleaned_list.append(cleaned_entry)
            
        self.data = cleaned_list
        print("Data sanitization complete.")

    def _clean_value(self, value):
        """
        Private method to clean individual string values.
        - Removes HTML tags (regex)
        - Normalizes whitespace
        - Standardizes missing data to ""
        """
        if value is None:
            return ""

        if not isinstance(value, str):
            return value

        # 1. Remove remnant HTML tags (e.g., <span>, <br>)
        value = re.sub(r'<[^>]+>', '', value)

        # 2. Replace non-breaking spaces and control characters
        value = value.replace('&nbsp;', ' ').replace('\n', ' ').replace('\r', '').replace('\t', ' ')

        # 3. Collapse multiple spaces into one
        value = re.sub(r'\s+', ' ', value)

        # 4. Strip leading/trailing whitespace
        value = value.strip()

        # 5. Standardize unavailable data to empty string ""
        # Meets requirement: 'SHOULD ensure unavailable data is maintained in a consistent format'
        if value.lower() in ["n/a", "na", "none", "unknown", ""]:
            return ""

        return value

    def _clean_program(self, value):
        """
        Clean the program field by removing redundant degree information
        that is already captured in the separate degree field.
        """
        value = self._clean_value(value)
        
        # Remove degree keywords (PhD, Masters, M.S., etc.)
        value = re.sub(r'\s*(PhD|Master\'?s?|M\.S\.|M\.A\.|M\.B\.A\.|M\.D\.|M\.E\.)\s*', ' ', value, flags=re.I)
        
        # Clean up any resulting multiple spaces
        value = re.sub(r'\s+', ' ', value).strip()
        
        return value

    def save_data(self, filename="cleaned_applicant_data.json"):
        """
        Saves the sanitized data to a JSON file.
        """
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(self.data, f, indent=4)
        print(f"Sanitized data saved to {filename}")

    def parse_stats(self, stats_text):
        data = {}
        # Extract GPA
        gpa_match = re.search(r'GPA\s*([\d\.]+)', stats_text, re.I)
        if gpa_match: data['gpa'] = gpa_match.group(1)
        
        # Extract GRE Total
        gre_match = re.search(r'GRE\s*(\d+)', stats_text, re.I)
        if gre_match: data['greScore'] = gre_match.group(1)
        
        # Extract GRE V
        gre_v_match = re.search(r'GRE V\s*(\d+)', stats_text, re.I)
        if gre_v_match: data['greV'] = gre_v_match.group(1)
        
        # Extract GRE AW
        gre_aw_match = re.search(r'GRE AW\s*([\d\.]+)', stats_text, re.I)
        if gre_aw_match: data['greAW'] = gre_aw_match.group(1)
        
        # Extract Student Type
        if 'International' in stats_text: data['US/International'] = 'International'
        elif 'American' in stats_text: data['US/International'] = 'American'
        
        # Extract Semester/Year
        sem_year = re.search(r'(Fall|Spring|Summer|Winter)\s*(\d{4})', stats_text, re.I)
        if sem_year:
            data['term'] = sem_year.group(1) + " " + sem_year.group(2)
            #data['semester'] = sem_year.group(1)
            #data['year'] = sem_year.group(2)
            
        return data

if __name__ == "__main__":
    # Initialize the cleaner
    cleaner = DataCleaner()
    
    # Load the raw data from scrape.py
    cleaner.load_data("applicant_data.json")
    
    # Perform cleaning
    cleaner.clean_data()
    
    cleaner.save_data("cleaned_applicant_data.json")